# wAlnut

*Think 1st principles and remember an axiom is not reality and that the "truth" is constantly changing*  

#### Table of Contents
- **[Short History of this Repository](#short-history-of-this-repository)**
- **[Why and Goals](#why-and-goals)**
- **[How](#how)**
- **[What](#what)**

## Short History of this Repository
<b>TLDR:</b> I was really wrong about how to build AGI 2 times since 2011 and now I'm trying to build a private neural lace until I find out I'm wrong about this too. 

In 2011 I watched [Jeff Hawkin's talk](https://www.ted.com/talks/jeff_hawkins_on_how_brain_science_will_change_computing) on 
artificial general intelligence(AGI) and I slowly became obsessed with building AGI. In 2012 this repo began as 
a full Java implementation of [Numenta's cortial learning algorithm v2](https://github.com/WalnutiQ/wAlnut/tree/4341e25d1fbd33a75708c4d428e3afc75f3fefe7). However, I started to doubt the long-term potential of the CLA after my experimental results didn't turn out as expected and in 2016 I read Dileep George's(previously 
co-founder of Numenta that left to start Vicarious) PhD thesis and I realized Dileep had a better approach to building AGI and 
this repo changed into a [Python implementation of the data structures and algorithms](https://github.com/WalnutiQ/wAlnut/tree/03093e1944bf1ff25a1c2cac672d5933f93fba78) outlined in Dileep George's PhD thesis 
[*How the Brain Might Work: A Hierarchical and Temporal Model for Learning and Recognition*](https://github.com/WalnutiQ/papers/blob/master/Dileep_George_PGM/HowTheBrainMightWork.pdf). Then in 2017 I came across [Elon Musk's perspective about AGI in the Future of Life Institute conversation](https://youtu.be/h0962biiZa4)
and read [Superintelligence by Nick Bostrom](https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/1501227742) with my notes [here](https://github.com/WalnutiQ/wAlnut/issues/345) and realized I was completely wrong 
about building AGI to help humanity in the first place. Now this repo's goal is to research how to increase human-code 
intelligence faster than code based intelligence. 

## Why and Goals

<b>TLDR:</b> Building artificial narrow intelligence(ANI) is fine but building AGI privately or pubicly is very bad for humanity because of simple reasons. Instead we need to increase human-computer intelligence with a privately built neural lace.  E-mail me your resume at quinnliu@vt.edu if you want to help :)

Since 2011 it was so easy for me to have confirmation bias toward only the positive effects of building AGI while a part of me 
avoided the question of `how do you control something that is smarter than all of humanity combined?`. The answer is you can 
not. I now believe AGI should not be built privately or publicly and instead one solution is to increase human intelligence 
with a privately built neural lace like [Neuralink](https://neuralink.com/) which you can read about [here](http://waitbutwhy.com/2017/04/neuralink.html). 

Today, many groups are trying to build AGI to help humanity. However, I believe strong AI should not be built because:

1. Humans are the domaint species on Earth because of our intelligence.
2. If we make another species (code based AGI) smarter than us then there is no way for us to control it 
   because it you can't control something that is more intelligent than all of humanity combined.
3. There is a very high chance that it will use humans for purposes we do not want. Just look at how we treat species 
   that are less intelligent than us.
4. We cannot stop the humans that are researching AGI so one solution is to increase human intelligence.

Now the question becomes `How do you increase human intelligence by orders of magnitude safely and faster than code based AGI?`. In order to answer this question we have to agree on a simple and clear definition of intelligence. 

We define intelligence in 2 parts. Intelligence is the <b>ability to predict the future</b> and <b>act on it in a way that is
beneficial to itself and others</b>. This means we can increase human intelligence in multiple ways. 

1. Increase breath, range, & accuracy of future predictions.  
2. Increase speed at which you can act on the world.
3. Increase ability to imagine beneficial situations for yourself and other intelligent agents.

If your interested in working on this together e-mail me your resume at quinnliu@vt.edu :)

~ Q

## How
To be updated...

## What
To be updated...
