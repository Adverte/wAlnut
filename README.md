# wAlnut

*Think 1st principles and remember an axiom is not reality and that the "truth" is constantly changing*  

#### Table of Contents
- **[History of this Repository](#short-history-of-this-repository)**
- **[Why and Goals](#why-and-goals)**

## History of this Repository
<b>TLDR:</b> I was wrong about how to build AGI 2 times since 2011 and now I'm learning how to increase human intelligence faster than code based intelligence unless I learn this is a bad idea haha

In 2011 I watched [Jeff Hawkin's talk](https://www.ted.com/talks/jeff_hawkins_on_how_brain_science_will_change_computing) on 
artificial general intelligence(AGI) and I became obsessed with building AGI to help humanity. I taught myself how to code and built 
an OO Java implementation of [Numenta's cortial learning algorithm(CLA) v2](https://github.com/WalnutiQ/wAlnut/tree/MARK_II). After running unsuccessful vision experiments using the CLA v2 I began to think there must be a better approach to building AGI. I found a better approach in Dileep George's [PhD thesis](https://github.com/WalnutiQ/papers/blob/master/Dileep_George_PGM/HowTheBrainMightWork.pdf) and the project changed into an [OO Python implementation of his PhD thesis](https://github.com/WalnutiQ/wAlnut/tree/MARK_III). While researching other approaches to AGI I came across [Elon Musk's perspective on AGI](https://youtu.be/h0962biiZa4)
and read [Superintelligence by Nick Bostrom](https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/1501227742) with my notes [here](https://github.com/WalnutiQ/wAlnut/issues/345) and realized I was completely wrong 
about building AGI to help humanity in the first place. Now the goal is to research how to increase human 
intelligence faster than code based intelligence. 

## Why and Goals

<b>TLDR:</b> Building artificial narrow intelligence(ANI) is fine but building AGI privately or pubicly is very bad for humanity because of simple reasons. Instead we need to increase human intelligence starting with a privately built neural lace.

Since 2011 it was so easy for me to have confirmation bias toward only the positive effects of building AGI while a part of me 
avoided the question:
  
`Q0: How do you control something that is smarter than all of humanity combined?`

The answer is you can not. I now believe AGI should not be built privately or publicly and instead one solution is to increase human intelligence with a privately built neural lace like [Neuralink](https://neuralink.com/) which you can read about [here](http://waitbutwhy.com/2017/04/neuralink.html). 

Today, many groups are trying to build AGI to help humanity. However, I believe AGI should not be built because:

1. Humans are the domaint species on Earth because of our intelligence.
2. If we make another species (code based AGI) smarter than us then there is no way for us to control it 
   because it you can't control something that is more intelligent than all of humanity combined.
3. There is a very high chance that it will use humans for purposes we do not want. Just look at how we treat species 
   that are less intelligent than us.
4. We cannot stop the humans that are researching AGI so now the question is:

`Q1: How do we solve the AGI control problem?`  
1. Use checklist of 100+ mental models.
2. Increase human intelligence faster than AGI.  
3. Figure out how to backwards time travel.  
4. Something I haven't or can't even imagine.

1 & 2 are the easiest to answer next so now the question becomes:
  
`Q2: How do you increase human intelligence by orders of magnitude safely and faster than code based AGI?`. 

In order to answer this question we have to agree on a simple and clear definition of intelligence. We define intelligence in 2 parts. Intelligence is the <b>ability to predict the future</b> and <b>act on it in a way that is
beneficial to itself and others</b>. This means we can increase human intelligence in multiple ways. 

1. Increase breath, range, & accuracy of future predictions.  
2. Increase speed at which you can act on the world.
3. Increase ability to imagine beneficial situations for yourself and other intelligent agents.

If your interested in working on this together e-mail me your resume at quinnliu@vt.edu :)

~ Q
