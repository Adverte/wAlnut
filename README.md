**[Why](#why) |**
**[How](#how) |**
**[Key Theories](#key-theories) |**
**[Files](#files)**

# wAlnut

"*I wish I'd had the courage to live a life true to myself, not the life others
expected of me. I mean it, promise this dying women that you will always be
true to yourself, that you will be brave enough to live the way you want to 
live regardless of what other poeple say.*" 

~ Grace

## Why 

I believe that intelligent machines will be able to solve many of our
hardest problems and will cause many new hard problems. Our hardest problems 
like cancer, mortality, and secrets of the universe involve understanding a 
lot of data and as humans we are limited by the processing power and size of 
our brains. But if we figure out the computational principles that make you 
and I intelligent, simulate them on a computer, scale it up to surpass the 
collective intelligence of the 7+ billion people on Earth we will have created 
intelligent machines that do not need to eat, sleep, or reproduce that can
work on our hardest problems much more efficiently than humans. 

Technology has always been used to do great good and great evil and even if we 
have the best intentions to do good, intelligent machines will cause many new 
problems. For example there will be massive job loss since most jobs 
can be replaced by intelligent machines. A possible solution to this hard 
problem will be to augment our brains and become super intelligent. 

The current short term goal is to experiment with a simplified visual pathway 
from an "eye" to experimental general learning algorithms to understand the key
principles of intelligence and rediscover other key principles. 

The long term goal of this repository is to rediscover all of the principles 
that make a system intelligent and store the code that can simulate the 
general learning abilitiy of a human brain in real time. 

After we understood the principles of flight we were able to build planes that
are much faster and can carry more weight than birds. After we understand
the human brain's computation principles we will be able to create intelligent
machines much more intelligent than humans with unimaginable capabilities. At 
first it will not have any emotions like you and I. This will be a good thing 
because it will force us to ask if it would be moral to create an super 
intelligent machine with emotions to help us. It may not necessarily be a 
good thing for the human race. For example look at how humans treat 
[intelligent pigs](http://modernfarmer.com/2014/03/pigheaded-smart-swine/).
We are more intelligent emotional machines compared to pigs and the future
super intelligent emotional machines will be much more intelligent compared to 
us.

If you are interested in becoming a researcher/developer I would be grateful
for your collaboration as I cannot do this alone. Please read
[how to contribute](https://github.com/WalnutiQ/wAlnut#how-to-contribute) to
get started. If you are interested in donating we take donations through Venmo.
For more information read [investors](#investors).

~ Q Liu

## How
Forget everything you know. 

Let go of your ego and understand building the first artificial general intelligence
is not some competition for fame, money, or respect but for seeking truth and 
making sure the most advanced known technology that evolution has created is
used to prevent valotile suffering for all organisms with conciousness. 

Remember "*what I cannot create I do not understand*" was said by Richard Feynman. 
Then think about what an intelligent machine needs to be able to do from first 
principles. Build a model using what you know from mathematics, machine 
learning, and neuroscience.  

Experiment with your model on tasks that only intelligent machines seem to be
good at. Be extremely open to ways to change the model. Remember that the
earth was born about 4.6 billion years ago and that it took evolution about
4.6 billion - 200,000 years to create the first homo sapian. This shit takes
time so if your frustrated go relax. 

Remember to focus on discovering principles of intelligence instead of getting
lost in the details of modeling everything a brain does or optimizing a 
mathematical algorithm. Evolution created intelligence but it also created many
properties of the brain that are not that important like nipples for the body.
There is a good reason why planes and helicopters do not look like birds. 

And as stupid as it sounds remember that it is the journey you go on that makes
everything worth it when you look back. Sometimes life will hit you with a 
hammer. When it does take time to regain your hope in humanity in any way you
feel is right and take as much time as you need. When you get back up you will
be a stronger version of yourself and ready to fail even harder again.

**[Setup development environment for Mac](#setup-development-environment-for-mac)** 
and then read **[how to contribute](#how-to-contribute)**.

#### Setup development environment for Mac
1. Go to the top right of this page and hit the Fork button. Then clone your forked 
   repository locally.

2. Intall [python](https://docs.python.org/devguide/setup.html#build-dependencies)
   and [pip](https://pip.pypa.io/en/stable/installing/)

3. Then run: `pip install virtualenv`
   - then `cd wAlnut` 
   - then `virtualenv wAlnut_environment`
   - then `source wAlnut_environment/bin/activate` 
   - then `pip install -r requirements.txt`
   - then `nosetests`
   - optionally type `deactivate` to leave the virtual environment

#### How to contribute
1. I am now looking to pay other developers a hourly rate of $20/hour(limited up
   to 5 hours/week) to code features for WalnutiQ. The most up to date income 
   and payment data can be viewed 
   [here](https://docs.google.com/spreadsheets/d/1GQoIOGFrmOWseQKszW8GSSTaCMKE_oxoxjhNWfERcCU/edit?usp=sharing). 
   
2. Sorry but you must meet these minimum requirements:
   - Know how to use Git & Github.com. If you don't know how I created a 1.5
     hour playlist on how to use Git & 
     Github [here](https://www.youtube.com/watch?v=44E8o-xuxWo&list=PLPXsMt57rLtgpwFBqZq4QKxrD9Hhc_8L4).
   - Be curious about how the human brain works. You don't need to be
     passionate about it right now. 
   - Written at least 2 thousand lines of Python in your life. 
   
3. E-mail quinnliu@vt.edu the following:
   - Link to source code of project you enjoyed working on the most. I am really 
     just looking for good object oriented design and good documention.
   - Why you want to work on wAlnut. 
  
4. If I e-mail you back for an interview during the interview we will discuss:
   - How everything will work. Expect to pair program with someone for a few 
     hours a week. 
   - If we both like what we hear we will walk you through making your 1st 
     commit to the repo's master branch!

5. For now we are using the Git workflow model described
   [here](https://github.com/WalnutiQ/wAlnut/issues/62) to contribute to this
   repository effectively. 

## Key Theories

1. **Theory 1:** 
   1 common learning algorithm in the neocortex of the brain
   - Supportive:
     + 1992 Paper [here](https://github.com/WalnutiQ/papers/blob/master/VisualProjectionsRouted.pdf)
       from Department of Brain and
       Cognitive Sciences at MIT.
       - Summary: A portion of wires of the optic nerve are routed to the 
         auditory cortex in ferrets. The neurons of this primary auditory 
         cortex(A1) with vision input did not work exactly like neurons in 
         primary visual cortex(V1). Neurons in rewired A1 had larger receptive 
         field sizes and other differences. However there are also 
         similarities including:
         + rewired A1 neurons showed orientation and direction selectivity.
         + similar proportions of simple, complex, and nonoriented cells between
           rewired A1 and V1.
         + implies "*significant implications for possible commonalities in
           intracortical processing circuits between sensory cortices*".

     + 1988 Paper [here](https://github.com/WalnutiQ/papers/blob/master/VisualResponses.pdf)
       from Laboratoire des Neuroscience de la Vision at Universite de Paris.
       - Summary: Wires of the optic nerve were routed permanently to the
         main thalamic somatosensory nucleus in hamsters. After the hamsters
         grew up the neurons in the somatosensory cortex were recorded.
         The "*somatosensory neurons responded to visual stimulation of
         distinct receptive fields, and their response properties resembled,
         in several characteristic features, those of normal visual cortical
         neurons.*"
         + "*the same functional categories of neurons occurred in similar
           proportions, and the neurons' selectivity for the orientation or
           direction of movement of visual stimuli was comparable*" between
           normal hamsters and rewired hamsters.
         + "*These results suggest that thalamic nuclei or cortical areas at
           corresponding levels in the visual and somatosensory pathways perform
           similar transformations on their inputs*".

     + 2008 PhD thesis [here](https://github.com/WalnutiQ/papers/blob/master/HowTheBrainMightWork.pdf)
       by Dileep George from Stanford University
       - There is a idea in optimization algorithms called No Free Lunch
         theorem. No Free Lunch theorem "*state[s] that any two optimization 
         algorithms are equivalent when their performance is averaged across 
         all possible problems*".
       - "*On the surface, the NFL theorem seems to create problems for the
         idea of a common cortical algorithm. How can one mechanism/algorithm
         do very well on tasks as different as vision, audition and language?
         The answer comes from the part of the NFL theorem that talks about
         the assumptions that need to be exploited ... If the cortex is good
         at learning a wide variety of tasks using a common mechanism, then
         there must be something common about these seemingly different tasks.*".

   - Not supportive:
     + 2002 Paper [here](https://github.com/WalnutiQ/papers/blob/master/CorticalHeterogeneity.pdf)
       from Vision, Touch and Hearing Research Centre at The University of Queensland.
          - "*recent studies have revealed substantial variation in pyramidal
            cell structure in different cortical areas*".

     + 2008 PhD thesis [here](https://github.com/WalnutiQ/papers/blob/master/HowTheBrainMightWork.pdf)
       by Dileep George from Stanford University
          - "*Until we understand and explain the computational reason behind
            a large majority of such variations, the common cortical algorithm
            will have to be considered as a working hypothesis*".

   - Conclusion: If cortex X(arbitrary cortex) of the neocortex(contains visual cortex,
     auditory cortex, somatosensory cortex, and others..) can be given
     non-normal sensory input usually given to say cortex Y and then learn to
     process this new input similarily to how cortex X would process it, then 
     we can hypothesize that there is a common learning/predicting algorithm 
     in all cortices of the neocortex.

2. **Theory 2:** 
   The common learning algorithm efficiently learns about the
   world by making a specific set of assumptions about the world. This is the
   inductive bias of the common learning algorithm. To find all assumptions
   the question we need to ask is
   "*What is the basic set of assumptions that are specific enough to make
   learning feasible in a reasonable amount of time while being general
   enough to be applicable to a large class of problems?*" ~ Dileep George 

3. **Assumption 1:**
   Every input pattern is encoded into a sparse distributed representation of 
   the input stimuli.
   - Supportive:
     - Not possible to process every pixel in the input image.
   - Not supportive:
   - Conclusion: Specific enough to make learning feasible in a reasonable 
     amount of time while being general enough to be applicable to a large 
     class of problems.

4. **Assumption 2:** 
   If pattern B follows pattern A in time then they are causally related and 
   in the future pattern A should predict pattern B.
   - Supportive:
     - The brain is constantly making predictions about the future. 
   - Not supportive:
     - How does the brain make predictions multiple time steps into the future?
   - Conclusion: Yes, specific enough to make learning feasible and general
     enough for large class of problems. 

5. **Assumption 3:**   
   Manifold = all the images generated by the same object in a 
   high-dimensional space. 

   If object A occurs close together to object B in time than object C then
   object A and object B are more similar. This information is used to form
   manifolds aka invariant representations of the objects.
   - Supportive: 
     + A baby has to learn this way before it understands speech. 
   - Not supportive:
   - Conclusion: Yes, specific enough to make learning feasible and general
     enough for large class of problems. 

6. **Assumption 4:** 
   During the current time step of the common learning algorithm, it will 
   always recieve input about what muscles were used in the last time step. 
   - Supportive:
     + Consciouness doesn't get confused when the eye is moving 
       around. This means every region in the neocortex must be recieving input
       about the eye's sensori-motor movement so it can use it to accurately
       predict the future. 
  - Not supportive:
  - Conclusion: This assumption is specific enough to make learning feasible 
    in a reasonable amount of time while being general enough to be applicable 
    to a large class of problems.   

7. **Assumption 5:**
   Complex invariant representations are made up of less complex invariant
   representations in a hierarchy.
   - Supportive:
     + More ideas in the universe than neurons in the brain. Also the universe
       has natural hierarchies. 
     + The neocortex has a hierarchal structure. 
   - Not supportive:
   - Conclusion: The common learning algorithm first learns invariant 
     representations of object components then learns invariant 
     representations of more complex objects in terms of the invariant 
     representations of the components. 

8. **Assumption 6:**
   A common learning algorithm must be trained on a unlabeled *movie* of the
   world it is expected to learn to predict and classify. 
   
9. **Theory 3:** There is no such thing as free will.
   - Supportive:
   - Not Supportive:
   
10. **Theory 4:** Consciousness is the illusion of an object believing it has free will. 
    - Supportive:
    - Not Supportive:

## Files
 
If you are confused what a file is doing at a high level read
**[what are all the files here for](#what-are-all-the-files-here-for)**. 

#### What are all the files here for
  - .gitignore = contains names of files/folders not to add to this repository
    but keep in your local wAlnut folder
  - LICENSE.txt = GNU General Public License version 3
  - README.md = the file you are reading right now